{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "graph_net_orbits.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNdr8zLOXv5XELmiRHBcbhq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pablo-Lemos/orbits/blob/master/colab_orbits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJgjZ43KMFUN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        },
        "outputId": "b3bfbc2e-ccf7-490f-ea61-cae430c3f499"
      },
      "source": [
        "!pip install graph_nets matplotlib scipy \"tensorflow>=1.15,<2\" \"dm-sonnet<2\" \"tensorflow_probability<0.9\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: graph_nets in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.4.1)\n",
            "Requirement already satisfied: tensorflow<2,>=1.15 in /usr/local/lib/python3.6/dist-packages (1.15.3)\n",
            "Requirement already satisfied: dm-sonnet<2 in /usr/local/lib/python3.6/dist-packages (1.36)\n",
            "Requirement already satisfied: tensorflow_probability<0.9 in /usr/local/lib/python3.6/dist-packages (0.8.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from graph_nets) (0.9.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.6/dist-packages (from graph_nets) (0.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from graph_nets) (1.18.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from graph_nets) (47.3.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from graph_nets) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from graph_nets) (1.12.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from graph_nets) (2.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.15) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.15) (1.15.1)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.15) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.15) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.15) (1.12.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.15) (3.2.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.15) (1.30.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.15) (0.34.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.15) (0.8.1)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.15) (0.2.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.15) (0.2.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.15) (1.0.8)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.15) (3.10.0)\n",
            "Requirement already satisfied: semantic-version in /usr/local/lib/python3.6/dist-packages (from dm-sonnet<2) (2.8.5)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.6/dist-packages (from dm-sonnet<2) (0.5.5)\n",
            "Requirement already satisfied: cloudpickle==1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow_probability<0.9) (1.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow_probability<0.9) (4.4.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.15) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.15) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow<2,>=1.15) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.15) (1.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.15) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2pJ8LZEMio_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import sys\n",
        "\n",
        "import tensorflow_probability\n",
        "\n",
        "from graph_nets import blocks\n",
        "from graph_nets import utils_np\n",
        "from graph_nets import utils_tf\n",
        "from graph_nets.demos import models\n",
        "from graph_nets import modules\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from copy import deepcopy\n",
        "\n",
        "import random as rand\n",
        "\n",
        "import graph_nets as gn\n",
        "import sonnet as snt\n",
        "import tensorflow as tf\n",
        "import networkx as nx"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWY_CKBZO0Zf",
        "colab_type": "text"
      },
      "source": [
        "# Load functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HASFxBpoMyyd",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title simulate_orbits.py\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "#Define constants\n",
        "AU = 149.6e6 * 1000     # Astronomical Unit in meters.\n",
        "DAY = 24*3600. # Day in seconds\n",
        "YEAR = 365.25*DAY\n",
        "MSUN = 1.98892 * 10**30 # Solar mass\n",
        "MEARTH = 5.9742 * 10**24 # Earth mass\n",
        "G = 6.67428e-11/AU**3*MSUN*YEAR**2 # The gravitational constant G in AU**3 /MSUN/ YEAR^2\n",
        "\n",
        "class Body:\n",
        "    \"\"\"\n",
        "    A class to represent astronomical bodies (e.g. planets and stars)\n",
        "    Attributes\n",
        "    ---------- \n",
        "    name : str\n",
        "        the name of the body\n",
        "    mass : float\n",
        "        mass in kg\n",
        "    pos : float(3) \n",
        "        position of the body as array (x,y,z) in m\n",
        "    vel : float(3) \n",
        "        velcity of the body as array (vx, vy, vz) in m/s\n",
        "    acc : float(3) \n",
        "        acceleration of the body as array (ax, ay, az) in m/s^2\n",
        "    orbit : ls\n",
        "        a list where the orbit is stored\n",
        "    Methods\n",
        "    -------\n",
        "    interaction(other) \n",
        "        Returns the acceleration due to gravitational interaction with another\n",
        "        body\n",
        "    update(delta_time)\n",
        "        Updates the position and velocity of the body after a time step\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ---------- \n",
        "        name : str\n",
        "            the name of the body\n",
        "        mass : float\n",
        "            mass in kg\n",
        "        pos : float(3) \n",
        "            position of the body as array (x,y,z) in m\n",
        "        vel : float(3) \n",
        "            velocity of the body as array (vx, vy, vz) in m/s\n",
        "        acc : float(3) \n",
        "            acceleration of the body as array (ax, ay, az) in m/s^2\n",
        "        orbit : ls\n",
        "            a list where the orbit is stored\n",
        "        \"\"\"\n",
        "\n",
        "        self.name = \"\" \n",
        "        self.mass = 0.\n",
        "        self.pos = np.zeros(3)\n",
        "        self.vel = np.zeros(3)\n",
        "        self.acc = np.zeros(3)\n",
        "        self.orbit = []\n",
        "    def initiate(self, radial_pos, total_vel):\n",
        "        \"\"\"\n",
        "        Randomly generate an initial position and velocity given a radial position\n",
        "        and a total velocity. \n",
        "        \"\"\"\n",
        "\n",
        "        # Create unitary vector, for now, we keep z = 0\n",
        "        u = random_two_vector()\n",
        "\n",
        "        # Define the initial position\n",
        "        x, y = radial_pos*u\n",
        "        z = 0.\n",
        "\n",
        "        # Define the initial velocity \n",
        "        vy, vx = total_vel*u\n",
        "\n",
        "        self.pos = np.array([x, y, 0])\n",
        "        self.vel = np.array([vx, -vy, 0])\n",
        "\n",
        "    def interaction(self, other):\n",
        "        \"\"\"Returns the acceleration due to gravitational interaction with \n",
        "        another body\n",
        "        \n",
        "        Parameters \n",
        "        ----------\n",
        "        other : Body\n",
        "            The astronomical body whose gravitational pull we are computing\n",
        "        \"\"\"\n",
        "    \n",
        "        # Compute distance to the other body\n",
        "        delta_pos = other.pos - self.pos\n",
        "        dist = np.sum(delta_pos**2.)**0.5\n",
        "        \n",
        "        #Calculate the acceleration using Newtonian Gravity\n",
        "        self.acc += G*other.mass*delta_pos/dist**3.\n",
        "\n",
        "    def update(self, delta_time):\n",
        "        \"\"\"Updates the position and velocity of the body after a time step\n",
        "        Parameters\n",
        "        ----------\n",
        "        delta_t : float \n",
        "            The size of the time step in seconds\n",
        "        \"\"\"\n",
        "\n",
        "        self.vel += self.acc*delta_time\n",
        "        self.pos += self.vel*delta_time\n",
        "\n",
        "def random_two_vector():\n",
        "    \"\"\"\n",
        "    Generates a random 2D unitary vector\n",
        "    Returns:\n",
        "    --------\n",
        "    x,y: float\n",
        "        Coordinates of the unitary vector (x^2 + y^2 = 1)\n",
        "    \"\"\"\n",
        "    phi = np.random.uniform(0,np.pi*2)\n",
        "    x = np.cos(phi)\n",
        "    y = np.sin(phi)\n",
        "    return np.array([x,y])\n",
        "\n",
        "def simulate(bodies, total_time, delta_time):\n",
        "    \"\"\"\n",
        "    Simulates the orbits for a certain period of time, and stores the results\n",
        "    as a panda array. \n",
        " \n",
        "    Parameters\n",
        "    ----------\n",
        "    bodies : list\n",
        "        The bodies that will interact in the simulation\n",
        "    total_time : float\n",
        "        The amount of time (in seconds) that the simulation will last for\n",
        "    time_step : float\n",
        "        The size of the time steps in the simulation in seconds\n",
        "    \"\"\"\n",
        "\n",
        "    time = 0 # Current time\n",
        "\n",
        "    while time<total_time: \n",
        "        for body in bodies: \n",
        "            body.acc = (0,0,0) # Restart acceleration\n",
        "            for other_body in bodies: \n",
        "                if body is not other_body: # Not sum over interaction with self\n",
        "                    # Sum over interactions with all other bodies\n",
        "                    body.interaction(other_body) \n",
        "\n",
        "            body.update(delta_time) # Update position and velocity of each body\n",
        "            body.orbit.append(np.concatenate(\n",
        "             (body.pos, body.vel))) # Store position of each body (in AU)\n",
        "\n",
        "        time += delta_time # Update total time\n",
        "\n",
        "    # Create the pandas DataFrame for each orbit\n",
        "    orbits = []\n",
        "    for body in bodies:\n",
        "        file_name = './'+body.name # File name to use for saving\n",
        "        \n",
        "        # Store as pandas array\n",
        "        # df = pd.DataFrame(body.orbit, columns = ['x[AU]', 'y[AU]', 'z[AU]'])\n",
        "        # df.to_pickle(file_name)\n",
        " \n",
        "        # Store as numpy array\n",
        "        orbits.append(np.asarray(body.orbit)) #convert orbit into numpy array\n",
        "\n",
        "    np.save(file_name, orbits)#, header = 'x[AU]', 'y[AU]', 'z[AU]') \n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    The main function. Defines the bodies and parameters to be used in the simulation, \n",
        "    and starts it\n",
        "    \"\"\"\n",
        "\n",
        "    delta_time = 1*DAY/YEAR # The time interval to be used in years\n",
        "    total_time = 400*DAY/YEAR # Total time of the Simulation in years\n",
        "\n",
        "    # Define Astronomical bodies. Data taken from: \n",
        "    # http://nssdc.gsfc.nasa.gov/planetary/factsheet/\n",
        "\n",
        "    # Sun\n",
        "    sun = Body() \n",
        "    sun.name = 'Sun'\n",
        "    sun.mass = 1./SUN # Solar masses\n",
        "    sun.pos = np.zeros(3)  \n",
        "    sun.vel = np.zeros(3) \n",
        "\n",
        "    # Mercury\n",
        "    mercury = Body()\n",
        "    mercury.name = 'Mercury'\n",
        "    mercury.mass = 0.33011 * 10**24/MSUN # Solar masses\n",
        "    mercury.pos = np.array([0.387, 0., 0.]) #AU\n",
        "    mercury.vel = np.array([0., -47.36 * 1000/AU*YEAR, 0.]) #AU/YEAR \n",
        "\n",
        "    #Venus\n",
        "    venus = Body()\n",
        "    venus.name = 'Venus'\n",
        "    venus.mass = 4.8685 * 10**24/MSUN # Solar masses\n",
        "    venus.pos = np.array([0.723, 0., 0.]) #AU\n",
        "    venus.vel = np.array([0.,-35.02 * 1000/AU*YEAR, 0.]) #AU/Y\n",
        "\n",
        "    # Earth\n",
        "    earth = Body()\n",
        "    earth.name = 'Earth'\n",
        "    earth.mass = MEARTH/MSUN # Solar masses\n",
        "    earth.pos = np.array([-1.,0.,0.]) # AU\n",
        "    earth.vel = np.array([0.,29.783*1000/AU*YEAR,0.])# AU/Y\n",
        "\n",
        "    #Run the simulation\n",
        "    simulate([sun, mercury, venus, earth], total_time, delta_time)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziBEKyZmOttV",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title functions for learning\n",
        "\n",
        "def get_orbital_velocity(radius, mass_planet, mass_star, G, ellipcity_noise = 0):\n",
        "    \"\"\"Calculate the initial velocity required to keep an orbit\n",
        "\n",
        "    Parameters\n",
        "    ---------- \n",
        "    radius : float\n",
        "      the radial distance from the body to the center of the orbit\n",
        "    mass_planet : float\n",
        "      mass of the planet orbiting\n",
        "    mass_star : float\n",
        "      mass of the body at the center of the orbit\n",
        "    G : float \n",
        "      Gravitational Constant\n",
        "    noise: float\n",
        "      The maximum fractional amount by which the initial velocity is perturbed. \n",
        "      Defaults to zero\n",
        "\n",
        "    Returns\n",
        "    ---------- \n",
        "    velocity : float\n",
        "      the orbital velocity\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    velocity = np.sqrt(G*mass_star/radius)\n",
        "\n",
        "    # Add noise\n",
        "    if ellipcity_noise > 0:\n",
        "        delta_vel = np.random.normal(0, ellipcity_noise, size = np.shape(velocity))\n",
        "        velocity *= (1.+delta_vel)\n",
        "\n",
        "    return np.array(velocity)\n",
        "\n",
        "def get_trajectory(planets, num_time_steps):\n",
        "    '''\n",
        "    Calculate real trajectory using Euler integration\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    planets : ls\n",
        "        A list of planets using the Body class\n",
        "    num_time_steps : float\n",
        "        The number of integration steps    \n",
        "      \n",
        "    Returns\n",
        "    -------\n",
        "    x_traj, p_traj: np.array([num_time_steps, nplanets, 2])\n",
        "        The positions and momenta of the trajectory for each planet\n",
        "    '''\n",
        "    \n",
        "    nplanets = len(planets)\n",
        "    x_traj = np.zeros([num_time_steps, nplanets, 2])\n",
        "    p_traj = np.zeros([num_time_steps, nplanets, 2])\n",
        "    for i in range(num_time_steps):\n",
        "        pos = []\n",
        "        mom = []\n",
        "        for planet in planets:\n",
        "            pos.append(planet.orbit[i][0:2])\n",
        "            mom.append(planet.orbit[i][3:5]*planet.mass)\n",
        "        \n",
        "        x_traj[i] = np.array(pos) #km\n",
        "        p_traj[i] = np.array(mom)#km/s\n",
        "\n",
        "    return x_traj, p_traj\n",
        "\n",
        "def get_input_graph(planets, xtraj, t, noise_level = 0.0):\n",
        "    '''\n",
        "    Convert a given time into a GraphNets graph that can be used to train a model\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    planets : ls\n",
        "        A list of planets using the Body class\n",
        "    xtraj: np.array([num_time_steps, nplanets, 2])\n",
        "        The positions and momenta of the trajectory for each planet\n",
        "    t: int\n",
        "        The time at which the trajectory is evaluated\n",
        "    noise_level: float\n",
        "        Fractional noise added to the training, defaults to 0.05\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    graph_dict: dict\n",
        "        A dictionary containing globals, edges, nodes, senders and receivers\n",
        "    '''\n",
        "    nplanets = len(planets)\n",
        "    nodes, edges, senders, receivers = [], [], [], []\n",
        "    for i in range(nplanets):\n",
        "        noise_mass = np.random.normal(0, noise_level)\n",
        "        mass = planets[i].mass#*(1+noise_mass)\n",
        "        nodes.append([mass]) #Use Mercury's mass for units to normalize\n",
        "        for j in range(nplanets):\n",
        "            # I do this instead of if i != j, so the distances and forces are not duplicate, this\n",
        "            # improves the model. I am basically telling the model that F(ij)=F(ji)\n",
        "            if i > j:\n",
        "                d = xtraj[t,j,:] - xtraj[t,i,:]\n",
        "                if noise_level > 0:\n",
        "                    noise_dist = tf.random.normal([2], 0, noise_level, tf.float32) \n",
        "                    edges.append(d*(1+noise_dist))\n",
        "                else:\n",
        "                    edges.append(d)\n",
        " \n",
        "                receivers.append(i)\n",
        "                senders.append(j)\n",
        "    \n",
        "    return{\n",
        "      \"globals\": [G],\n",
        "      \"nodes\": nodes,\n",
        "      \"edges\": edges, \n",
        "      \"receivers\": receivers, \n",
        "      \"senders\": senders \n",
        "    }  \n",
        "\n",
        "def generate_batch_random(planets, x_traj, dp_traj, num_time_steps, batch_size, norm_factor = 1, ellipcity_noise = 0):\n",
        "    ''' Generate a batch of points randomly chosen for training\n",
        "    '''\n",
        "    x_traj_ls = []\n",
        "    p_traj_ls = []\n",
        "    dp_traj_ls = []\n",
        "    traj_len = len(x_traj)\n",
        "    nplanets = len(planets)\n",
        "    x_batch_np = np.zeros([batch_size, num_time_steps, nplanets, 2])\n",
        "    dp_batch_np = np.zeros([batch_size, num_time_steps, nplanets, 2])\n",
        "    t_array = np.random.choice(traj_len-1, batch_size*num_time_steps)\n",
        "    k = 0\n",
        "    for i in range(batch_size):\n",
        "        for j in range(num_time_steps):\n",
        "            x_batch_np[i,j] = x_traj[t_array[k]]\n",
        "            dp_batch_np[i,j] = dp_traj[t_array[k]]\n",
        "            k+=1\n",
        "            \n",
        "    x_batch = tf.convert_to_tensor(x_batch_np, dtype=np.float32)\n",
        "    dp_batch = tf.convert_to_tensor(dp_batch_np, dtype=np.float32)\n",
        "    return x_batch, dp_batch"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CmD7oMTQrYR",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Integration Functions\n",
        "\n",
        "def get_distances(x, input_graph):\n",
        "    '''\n",
        "    Convert positions to distances\n",
        "    '''\n",
        "    new_graph = input_graph.replace(nodes = x)\n",
        "    e1 = blocks.broadcast_sender_nodes_to_edges(new_graph)\n",
        "    e2 = blocks.broadcast_receiver_nodes_to_edges(new_graph)\n",
        "    dx = e1 - e2\n",
        "    return dx\n",
        "\n",
        "def model_gn(dx, input_graph, num_processing_steps, normalization = 1):\n",
        "    '''\n",
        "    Use the model to go from dx to dp\n",
        "    '''\n",
        "    graph = input_graph.replace(edges = dx)\n",
        "    outputs = model(graph, num_processing_steps)\n",
        "    outputs_p = get_momentum_update(outputs)\n",
        "    output = sum(outputs_p)/num_processing_steps\n",
        "    dp = output*normalization\n",
        "\n",
        "    edges = [output.edges for output in outputs]\n",
        "    forces_unnorm = sum(edges)/num_processing_steps\n",
        "    forces = forces_unnorm*normalization\n",
        "    return dp, forces\n",
        "\n",
        "def get_leapfrog_step(x0, ph, delta_time, input_graph, model, num_processing_steps, normalization = 1):\n",
        "    \n",
        "    delta_x = delta_time/input_graph.nodes\n",
        "    \n",
        "    x1 = x0 + ph*delta_x\n",
        "    \n",
        "    dx = get_distances(x0, input_graph)\n",
        "    \n",
        "    dp, force = model(dx, input_graph, num_processing_steps, normalization)\n",
        "    ph3 = ph + dp\n",
        "\n",
        "    return x1, ph3, dp, force\n",
        "\n",
        "def leapfrog_integration(x0, p0, delta_time, input_graph, num_steps, model, num_processing_steps, normalization = 1):\n",
        "    '''\n",
        "    Learn the orbit through leapfrom integration\n",
        "    '''\n",
        "    def body(i, x0, p0, x_pred, dp_pred, f_pred):\n",
        "        x, ph, dp, force =  get_leapfrog_step(\n",
        "            x0, p0, delta_time, \n",
        "            input_graph, \n",
        "            model, \n",
        "            num_processing_steps, \n",
        "            normalization)\n",
        "        return i+1, x, ph, x_pred.write(i, x), dp_pred.write(i-1, dp/normalization), f_pred.write(i-1, force)\n",
        "    \n",
        "    # Distance\n",
        "    dx = get_distances(x0, input_graph)\n",
        "\n",
        "    # Model predict*norm_p = F*dt\n",
        "    # (ph = phalf)\n",
        "    dph, fh = model(dx, input_graph, num_processing_steps, normalization)\n",
        "    ph = p0 + 0.5*dph\n",
        "    x = tf.identity(x0)\n",
        "    \n",
        "    i = 0\n",
        "\n",
        "    x_pred = tf.TensorArray(\n",
        "      dtype=tf.float32, size=num_steps, element_shape=x0.shape)\n",
        "    dp_pred = tf.TensorArray(\n",
        "      dtype=tf.float32, size=num_steps-1, element_shape=x0.shape)\n",
        "    f_pred = tf.TensorArray(\n",
        "      dtype=tf.float32, size=num_steps-1, element_shape=fh.shape)\n",
        "\n",
        "    x_pred = x_pred.write(0, x0)\n",
        "    \n",
        "    _, _, _, x_pred, dp_pred, f_pred = tf.while_loop(\n",
        "    lambda i, *unused_args: i < num_steps,\n",
        "        body,\n",
        "        loop_vars = [1, x0, ph, x_pred, dp_pred, f_pred]\n",
        "    )\n",
        "    return x_pred.stack(), dp_pred.stack(), f_pred.stack()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmOH7iUKPJpC",
        "colab_type": "text"
      },
      "source": [
        "# Input parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ks5biYSxO26m",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title generate training data\n",
        "\n",
        "# Global constants\n",
        "DAY = 24*3600. # Day in seconds\n",
        "YEAR = 365.25*DAY #Year\n",
        "delta_time = (2/24.)*DAY/YEAR # 2 hours\n",
        "#delta_time = 0.1*DAY/YEAR # 1 hour\n",
        "\n",
        "total_time_traj = 10 #Years\n",
        "num_time_steps_total = int(total_time_traj/delta_time)\n",
        "num_time_steps_test = 4000\n",
        "\n",
        "batch_size_tr = 500\n",
        "total_time_tr = 200*delta_time\n",
        "num_time_steps_tr = int(total_time_tr/delta_time)\n",
        "\n",
        "batch_size_table = 50\n",
        "total_time_table = 200*delta_time\n",
        "num_time_steps_table = int(total_time_table/delta_time)\n",
        "\n",
        "num_processing_steps_tr = 1\n",
        "patience = 20\n",
        "d_patience = 1e-5\n",
        "#d_patience = 0\n",
        "noise_level = 0.05\n",
        "\n",
        "# How much time between logging and printing the current results.\n",
        "log_every_iterations = 1000\n",
        "num_training_iterations = 150000\n",
        "\n",
        "sun = Body()\n",
        "sun.name = 'Sun'\n",
        "sun.mass = 1 # solar masses\n",
        "sun.pos = np.zeros(3) \n",
        "\n",
        "mercury = Body()\n",
        "mercury.name = 'Mercury'\n",
        "mercury.mass = 0.33011 * 10**24/MSUN # Earth masses\n",
        "pos_mercury = 0.387 # AU\n",
        "vel_mercury = get_orbital_velocity(pos_mercury, \n",
        "                                   mercury.mass, \n",
        "                                   sun.mass, \n",
        "                                   G,\n",
        "                                   ellipcity_noise = 0.01\n",
        "                                  )\n",
        "mercury.initiate(pos_mercury, vel_mercury)\n",
        "    \n",
        "venus = Body()\n",
        "venus.name = 'Venus'\n",
        "venus.mass = 4.8685 * 10**24/MSUN # Earth masses\n",
        "pos_venus = 0.723 # AU\n",
        "vel_venus = get_orbital_velocity(pos_venus, \n",
        "                                 venus.mass, \n",
        "                                 sun.mass, \n",
        "                                 G,\n",
        "                                ellipcity_noise = 0.01)\n",
        "venus.initiate(pos_venus, vel_venus)\n",
        "\n",
        "earth = Body()\n",
        "earth.name = 'Earth'\n",
        "earth.mass =MEARTH/MSUN # Earth masses\n",
        "pos_earth = 1 # AU\n",
        "vel_earth = get_orbital_velocity(pos_earth, \n",
        "                                 earth.mass, \n",
        "                                 sun.mass, \n",
        "                                 G, \n",
        "                                ellipcity_noise = 0.01)\n",
        "earth.initiate(pos_earth, vel_earth)\n",
        "\n",
        "mars = Body()\n",
        "mars.name = 'Mars'\n",
        "mars.mass =0.642 * 10**24/MSUN # Earth masses\n",
        "pos_mars = 1.52341740516 # AU\n",
        "vel_mars = get_orbital_velocity(pos_mars, \n",
        "                                 mars.mass, \n",
        "                                 sun.mass, \n",
        "                                 G, \n",
        "                                ellipcity_noise = 0.01)\n",
        "mars.initiate(pos_mars, vel_mars)\n",
        "\n",
        "\n",
        "sun.vel = -(np.array(mercury.vel)*mercury.mass + \n",
        "            np.array(venus.vel)*venus.mass +\n",
        "            np.array(earth.vel)*earth.mass #+\n",
        "            #np.array(mars.vel)*mars.mass\n",
        "            )/sun.mass\n",
        "\n",
        "# Center at zero (improves stability)\n",
        "sun.pos = -(np.array(mercury.pos)*mercury.mass + \n",
        "            np.array(venus.pos)*venus.mass +\n",
        "            np.array(earth.pos)*earth.mass #+ \n",
        "            #np.array(mars.pos)*mars.mass\n",
        "            )/sun.mass\n",
        "#sun.pos = np.zeros(3)\n",
        "\n",
        "planets = [sun, mercury, venus, earth]#, mars]\n",
        "nplanets = len(planets)\n",
        "    \n",
        "planets_gn = deepcopy(planets)\n",
        "\n",
        "simulate(planets, total_time_traj, delta_time)\n",
        "\n",
        "x_traj_np, p_traj_np = get_trajectory(planets, num_time_steps_total)\n",
        "dp_traj_np = p_traj_np[1:] - p_traj_np[:-1]\n",
        "\n",
        "p_norm = np.std(dp_traj_np)\n",
        "\n",
        "x_traj_test = tf.convert_to_tensor(x_traj_np[:num_time_steps_test], dtype=np.float32)\n",
        "p_traj_test = tf.convert_to_tensor(p_traj_np[:num_time_steps_test], dtype=np.float32)\n",
        "dp_traj_norm = tf.convert_to_tensor(\n",
        "    dp_traj_np[:num_time_steps_test-1]/p_norm, dtype=np.float32)\n",
        "\n",
        "\n",
        "x_traj_np_tr = x_traj_np[num_time_steps_test:]\n",
        "dp_traj_np_tr = dp_traj_np[num_time_steps_test:]/p_norm\n",
        "\n",
        "\n",
        "input_dict_test = get_input_graph(planets, x_traj_test, 0, noise_level = 0.0)\n",
        "\n",
        "input_graph_test = utils_tf.data_dicts_to_graphs_tuple([input_dict_test])\n",
        "input_graph_test_old = utils_tf.data_dicts_to_graphs_tuple([input_dict_test])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRboV-qUTmeQ",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdEMDS8PTqT2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_momentum_update(output_ops):\n",
        "    reducer = tf.unsorted_segment_sum\n",
        "    \n",
        "    dp = []\n",
        "    for output_op in output_ops:\n",
        "        b1 = blocks.ReceivedEdgesToNodesAggregator(reducer=reducer)(output_op)\n",
        "        b2 = blocks.SentEdgesToNodesAggregator(reducer=reducer)(output_op)\n",
        "        dp.append(b1-b2)\n",
        "    return dp\n",
        "\n",
        "\n",
        "def create_loss_ops(target_op, output_ops):\n",
        "    \"\"\"Create supervised loss operations from targets and outputs.\n",
        "\n",
        "    Args:\n",
        "        target_op: The target velocity tf.Tensor.\n",
        "        output_ops: The list of output graphs from the model.\n",
        "\n",
        "    Returns:\n",
        "        A list of loss values (tf.Tensor), one per output op.\n",
        "    \"\"\"\n",
        "    loss_ops = [\n",
        "        tf.reduce_mean(\n",
        "            tf.reduce_sum((output_op - target_op)**2, axis=-1))\n",
        "        for output_op in output_ops\n",
        "    ]\n",
        "    return loss_ops"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6GqLhNVToAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_traj_tr, dp_traj_tr = generate_batch_random(planets, x_traj_np_tr, dp_traj_np_tr, num_time_steps=num_time_steps_tr, batch_size=batch_size_tr)\n",
        "\n",
        "# Create the graph network.\n",
        "graph_net_module = modules.GraphNetwork(\n",
        "        edge_model_fn=lambda: snt.nets.MLP([128, 128, 128, 128, 2]),\n",
        "        node_model_fn=lambda: snt.nets.MLP([0]),\n",
        "        global_model_fn=lambda: snt.nets.MLP([0]),\n",
        "    edge_block_opt={\"use_edges\": True,\n",
        "                   \"use_receiver_nodes\": True, \n",
        "                   \"use_sender_nodes\": True, \n",
        "                   \"use_globals\": False},\n",
        "    node_block_opt={\"use_nodes\": True,\n",
        "                   \"use_received_edges\": False, \n",
        "                   \"use_sent_edges\": False, \n",
        "                   \"use_globals\": False},\n",
        "    )\n",
        "\n",
        "def model(graph, num_processing_steps):\n",
        "    \n",
        "    output_ops = [graph_net_module(graph)]\n",
        "    return output_ops"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMyhcSrWUO2C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = tf.random_uniform([], minval=0, maxval=num_time_steps_tr - 1, dtype=tf.int32)\n",
        "input_dict_tr = []\n",
        "for i in range(batch_size_tr):\n",
        "    input_dict_tr.append(get_input_graph(planets, x_traj_tr[i], t, noise_level = noise_level))\n",
        "    \n",
        "input_graph_tr = utils_tf.data_dicts_to_graphs_tuple(input_dict_tr)\n",
        "output_model = model(input_graph_tr, num_processing_steps_tr)\n",
        "output_ops_tr = get_momentum_update(output_model)\n",
        "target_nodes_tr = tf.reshape(dp_traj_tr[:,t], shape=[batch_size_tr*nplanets, 2])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1GOIPBJTtKS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "outputId": "4499b244-cf0d-476d-d868-30bbdc0c3956"
      },
      "source": [
        "# Integration (test)\n",
        "x0 = x_traj_test[0]\n",
        "p0 = p_traj_test[0]\n",
        "xp, pp, fp = leapfrog_integration(\n",
        "    x0, p0, \n",
        "    delta_time, \n",
        "    input_graph_test, \n",
        "    num_time_steps_test, \n",
        "    model_gn, \n",
        "    num_processing_steps_tr,\n",
        "    normalization = p_norm)\n",
        "\n",
        "loss_test = tf.reduce_mean(\n",
        "    tf.reduce_sum(\n",
        "    (pp - dp_traj_norm)**2., axis = -1\n",
        "    ))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/sonnet/python/modules/basic.py:127: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/sonnet/python/modules/basic.py:132: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAYKEMKQUBUk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training loss.\n",
        "loss_ops_tr = create_loss_ops(target_nodes_tr, output_ops_tr)\n",
        "# Training loss across processing steps.\n",
        "loss_op_tr = sum(loss_ops_tr) / num_processing_steps_tr"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pP-nesHtUEWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Optimizer.\n",
        "learning_rate = 1e-5\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "step_op = optimizer.minimize(loss_op_tr)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHXUNG-aUR-v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This cell resets the Tensorflow session, but keeps the same computational\n",
        "# graph.\n",
        "\n",
        "try:\n",
        "    sess.close()\n",
        "except NameError:\n",
        "    pass\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "nsteps_no_improvement = 0\n",
        "last_iteration = 0\n",
        "previous_loss = 0\n",
        "iterations = []\n",
        "losses_tr = []\n",
        "losses_test = []\n",
        "losses_table = []"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41_UHfGfUVyG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "89234318-f061-4c63-9ae9-b66a5a08b1d3"
      },
      "source": [
        "start_time = time.time()\n",
        "last_log_time = start_time\n",
        "\n",
        "print(\"# (iteration number), T (elapsed seconds), \"\n",
        "      \"Ltr (training 1-step loss), Ltest (test loss)\")\n",
        "\n",
        "for iteration in range(last_iteration, num_training_iterations):\n",
        "    last_iteration = iteration\n",
        "    train_values = sess.run({\n",
        "        \"step\": step_op,\n",
        "        \"loss\": loss_op_tr,\n",
        "        \"input_graph\": input_graph_tr,\n",
        "        \"target_nodes\": target_nodes_tr,\n",
        "        \"outputs\": output_ops_tr\n",
        "    })\n",
        "    the_time = time.time()\n",
        "    \n",
        "    if train_values[\"loss\"] >= (previous_loss - d_patience): \n",
        "        nsteps_no_improvement += 1\n",
        "    else: \n",
        "        nsteps_no_improvement = 0\n",
        "    \n",
        "    previous_loss = train_values[\"loss\"]\n",
        "        \n",
        "    if nsteps_no_improvement >= patience: \n",
        "        print('Convergence achieved')\n",
        "        print('Iterations = ', iteration)\n",
        "        print('Time = ', time.time() - start_time, 'seconds.')\n",
        "        print('Training 1-step loss = ', train_values[\"loss\"])\n",
        "        break\n",
        "    \n",
        "    if iteration%log_every_iterations == 0:\n",
        "        test_orbit = sess.run({\n",
        "            \"x_pred\": xp, \n",
        "            \"dp_pred\": pp,\n",
        "            \"f_pred\": fp, \n",
        "            \"loss\": loss_test\n",
        "        })\n",
        "\n",
        "        #table_orbit = sess.run({\n",
        "        #    \"x_pred\": xp_table,\n",
        "        #    \"dp_pred\": dp_table,\n",
        "        #    \"f_pred\": fp_table, \n",
        "        #    \"loss\": loss_table\n",
        "        #})\n",
        "\n",
        "        last_log_time = the_time\n",
        "        elapsed = time.time() - start_time\n",
        "        iterations.append(iteration)\n",
        "        losses_tr.append(train_values[\"loss\"])\n",
        "        losses_test.append(test_orbit[\"loss\"])\n",
        "        #losses_table.append(table_orbit[\"loss\"])\n",
        "        print(\n",
        "            \"# {:06d}, T {:.1f}, Ltr {:.6f}, Ltest {:.6f}\".format(\n",
        "                iteration, elapsed, train_values[\"loss\"], test_orbit[\"loss\"]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# (iteration number), T (elapsed seconds), Ltr (training 1-step loss), Ltest (test loss)\n",
            "# 000000, T 36.6, Ltr 1.963881, Ltest 2.957957\n",
            "# 001000, T 95.7, Ltr 0.347945, Ltest 1.116262\n",
            "# 002000, T 154.6, Ltr 0.156524, Ltest 1.484853\n",
            "# 003000, T 213.7, Ltr 0.106757, Ltest 1.318748\n",
            "# 004000, T 272.8, Ltr 0.048506, Ltest 0.908752\n",
            "# 005000, T 331.3, Ltr 0.015099, Ltest 0.192320\n",
            "# 006000, T 390.1, Ltr 0.007593, Ltest 0.023995\n",
            "# 007000, T 448.8, Ltr 0.005812, Ltest 0.018375\n",
            "# 008000, T 507.4, Ltr 0.004519, Ltest 0.016721\n",
            "# 009000, T 565.8, Ltr 0.004158, Ltest 0.016774\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uw7ZBW9mUmJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, axs = plt.subplots(ncols = 2, nrows = 1, figsize = (12, 6))\n",
        "\n",
        "ax = axs[0]\n",
        "ax.plot(iterations,losses_tr)\n",
        "ax.set_title('Training loss')\n",
        "ax.set_xlabel('iteration')\n",
        "ax.set_yscale('log')\n",
        "ax.set_xscale('log')\n",
        "ax.set_ylabel('Training loss')\n",
        "\n",
        "ax = axs[1]\n",
        "ax.set_title('Test loss')\n",
        "ax.plot(iterations,losses_test)\n",
        "ax.set_yscale('log')\n",
        "ax.set_xscale('log')\n",
        "ax.set_xlabel('iteration')\n",
        "ax.set_ylabel('Test loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phetubrrUyau",
        "colab_type": "text"
      },
      "source": [
        "# Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G98EuF3BUr-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get prediction as numpy array\n",
        "x_pred = test_orbit[\"x_pred\"]\n",
        "dp_pred = test_orbit[\"dp_pred\"]\n",
        "f_pred = test_orbit[\"f_pred\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTZv2ZU0U0f9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nsteps_plot = num_time_steps_test-1\n",
        "plt.rcParams.update({'font.size': 30})\n",
        "fig, axs =plt.subplots(nrows = 1, ncols = len(planets), figsize = (10*len(planets), 10))\n",
        "\n",
        "periods = np.array([225, 88, 225, 1000, 1500])\n",
        "factor = 10*periods\n",
        "\n",
        "axs[0].set_ylabel('P_y')\n",
        "for i in range(len(planets)):\n",
        "    ax = axs[i]\n",
        "    \n",
        "    shift = dp_traj_np[:,i,0].max()/factor[i]*np.arange(nsteps_plot)\n",
        "\n",
        "    ax.set_title(planets[i].name, fontsize = 32)\n",
        "    ax.scatter(dp_traj_np[:nsteps_plot,i,0]/p_norm+shift, dp_traj_np[:nsteps_plot,i,1]/p_norm+shift, label='Truth')\n",
        "    ax.scatter(dp_pred[:nsteps_plot,i,0]+shift, dp_pred[:nsteps_plot,i,1]+shift, label='Prediction')\n",
        "    ax.set_xlabel('P_x')\n",
        "\n",
        "plt.legend();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcUZGnIIU3Uf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nsteps_plot = num_time_steps_test\n",
        "plt.rcParams.update({'font.size': 30})\n",
        "fig, axs =plt.subplots(nrows = 1, ncols = len(planets), figsize = (10*len(planets), 10))\n",
        "\n",
        "periods = np.array([225, 88, 225, 1000, 1500])\n",
        "factor = 10*periods\n",
        "\n",
        "axs[0].set_ylabel('Y [km]')\n",
        "for i in range(len(planets)):\n",
        "    ax = axs[i]\n",
        "    \n",
        "    shift = x_traj_np[:,i,0].max()/factor[i]*np.arange(nsteps_plot)\n",
        "\n",
        "    ax.set_title(planets[i].name, fontsize = 32)\n",
        "    ax.scatter(x_traj_np[:nsteps_plot,i,0]+shift, x_traj_np[:nsteps_plot,i,1]+shift, label='Truth')\n",
        "    ax.scatter(x_pred[:nsteps_plot,i,0]+shift, x_pred[:nsteps_plot,i,1]+shift, label='Prediction')\n",
        "    ax.set_xlabel('X [km]')\n",
        "\n",
        "plt.legend();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uZni1TaU8g4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}