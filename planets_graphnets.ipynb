{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "\n",
    "from graph_nets import blocks\n",
    "from graph_nets import utils_tf\n",
    "from graph_nets.demos import models\n",
    "from graph_nets import modules\n",
    "from matplotlib import pyplot as plt\n",
    "from simulate_orbits import *\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "import random as rand\n",
    "\n",
    "import graph_nets as gn\n",
    "import sonnet as snt\n",
    "import tensorflow as tf\n",
    "import networkx as nx\n",
    "\n",
    "# For debugging only\n",
    "#tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the tensorflow_graphics package\n",
    "\n",
    "def log10(x):\n",
    "    numerator = tf.log(x)\n",
    "    denominator = tf.log(tf.constant(10, dtype=numerator.dtype))\n",
    "    return numerator / denominator\n",
    "\n",
    "def cartesian_to_spherical_coordinates(point_cartesian, eps=None):\n",
    "    \"\"\"Function to transform Cartesian coordinates to spherical coordinates.\n",
    "    This function assumes a right handed coordinate system with `z` pointing up.\n",
    "    When `x` and `y` are both `0`, the function outputs `0` for `phi`. Note that\n",
    "    the function is not smooth when `x = y = 0`.\n",
    "    Note:\n",
    "      In the following, A1 to An are optional batch dimensions.\n",
    "    Args:\n",
    "      point_cartesian: A tensor of shape `[A1, ..., An, 3]`. In the last\n",
    "        dimension, the data follows the `x`, `y`, `z` order.\n",
    "      eps: A small `float`, to be added to the denominator. If left as `None`,\n",
    "        its value is automatically selected using `point_cartesian.dtype`.\n",
    "      name: A name for this op. Defaults to `cartesian_to_spherical_coordinates`.\n",
    "    Returns:\n",
    "      A tensor of shape `[A1, ..., An, 3]`. The last dimensions contains\n",
    "      (`r`,`theta`,`phi`), where `r` is the sphere radius, `theta` is the polar\n",
    "      angle and `phi` is the azimuthal angle.\n",
    "    \"\"\"\n",
    "    #with tf.compat.v1.name_scope(name, \"cartesian_to_spherical_coordinates\",\n",
    "    #                             [point_cartesian]):\n",
    "    #  point_cartesian = tf.convert_to_tensor(value=point_cartesian)\n",
    "\n",
    "    #shape.check_static(\n",
    "    #    tensor=point_cartesian,\n",
    "    #    tensor_name=\"point_cartesian\",\n",
    "    #    has_dim_equals=(-1, 3))\n",
    "\n",
    "    x, y, z = tf.unstack(point_cartesian, axis=-1)\n",
    "    radius = tf.norm(tensor=point_cartesian, axis=-1)\n",
    "    theta = tf.acos(\n",
    "        tf.clip_by_value(tf.divide(z, radius), -1., 1.))\n",
    "    phi = tf.atan2(y, x)\n",
    "    return tf.stack((log10(radius), theta, phi), axis=-1)\n",
    "\n",
    "def spherical_to_cartesian_coordinates(point_spherical, name=None):\n",
    "    \"\"\"Function to transform Cartesian coordinates to spherical coordinates.\n",
    "    Note:\n",
    "      In the following, A1 to An are optional batch dimensions.\n",
    "    Args:\n",
    "      point_spherical: A tensor of shape `[A1, ..., An, 3]`. The last dimension\n",
    "        contains r, theta, and phi that respectively correspond to the radius,\n",
    "        polar angle and azimuthal angle; r must be non-negative.\n",
    "      name: A name for this op. Defaults to 'spherical_to_cartesian_coordinates'.\n",
    "    Raises:\n",
    "      tf.errors.InvalidArgumentError: If r, theta or phi contains out of range\n",
    "      data.\n",
    "    Returns:\n",
    "      A tensor of shape `[A1, ..., An, 3]`, where the last dimension contains the\n",
    "      cartesian coordinates in x,y,z order.\n",
    "    \"\"\"\n",
    "    #with tf.compat.v1.name_scope(name, \"spherical_to_cartesian_coordinates\",\n",
    "    #                           [point_spherical]):\n",
    "    #point_spherical = tf.convert_to_tensor(value=point_spherical)\n",
    "\n",
    "    #shape.check_static(\n",
    "    #    tensor=point_spherical,\n",
    "    #    tensor_name=\"point_spherical\",\n",
    "    #    has_dim_equals=(-1, 3))\n",
    "\n",
    "    logr, theta, phi = tf.unstack(point_spherical, axis=-1)\n",
    "    r = tf.pow(logr, 10)\n",
    "    #r = asserts.assert_all_above(r, 0)\n",
    "    tmp = r * tf.sin(theta)\n",
    "    x = tmp * tf.cos(phi)\n",
    "    y = tmp * tf.sin(phi)\n",
    "    z = r * tf.cos(theta)\n",
    "    return tf.stack((x, y, z), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch_random(planets, x_traj, dp_traj, num_time_steps, batch_size, norm_factor = 1, ellipcity_noise = 0):\n",
    "    x_traj_ls = []\n",
    "    p_traj_ls = []\n",
    "    dp_traj_ls = []\n",
    "    traj_len = len(x_traj)\n",
    "    nplanets = len(planets)\n",
    "    x_batch_np = np.zeros([batch_size, num_time_steps, nplanets, 3])\n",
    "    dp_batch_np = np.zeros([batch_size, num_time_steps, nplanets, 3])\n",
    "    t_array = np.random.choice(traj_len-1, batch_size*num_time_steps)\n",
    "    k = 0\n",
    "    for i in range(batch_size):\n",
    "        for j in range(num_time_steps):\n",
    "            x_batch_np[i,j] = x_traj[t_array[k]]\n",
    "            dp_batch_np[i,j] = dp_traj[t_array[k]]\n",
    "            k+=1\n",
    "            \n",
    "    x_batch = tf.convert_to_tensor(x_batch_np, dtype=np.float32)\n",
    "    dp_batch = tf.convert_to_tensor(dp_batch_np, dtype=np.float32)\n",
    "    return x_batch, dp_batch\n",
    "\n",
    "def change_orbit_frame(orbits, masses, delta_time):\n",
    "    x_arr = orbits[:,:3,:]\n",
    "    v_arr = orbits[:,3:,:]\n",
    "    p_arr = v_arr[:,:,:]*masses[:,np.newaxis,np.newaxis]\n",
    "    \n",
    "    #x_cm_0 = np.sum(x_arr[:,:,0]*masses[:,np.newaxis], axis = 0)/np.sum(masses)\n",
    "    v_ref = np.sum(p_arr[:,:,:], axis = 0)/np.sum(masses)\n",
    "    x_cm = np.sum(x_arr[:,:,:]*masses[:,np.newaxis,np.newaxis], axis = 0)/np.sum(masses)\n",
    "    \n",
    "    v_new = v_arr - v_ref\n",
    "    ntime = len(x_arr[0,0])\n",
    "    t = np.arange(0, ntime*delta_time, delta_time)\n",
    "    #x_new = x_arr - v_ref*t - x_cm_0[np.newaxis,:,np.newaxis]\n",
    "    x_new = x_arr - x_cm\n",
    "    p_new = v_new*masses[:,np.newaxis,np.newaxis]\n",
    "    \n",
    "    return x_new.transpose(2,0,1), p_new.transpose(2,0,1)\n",
    "\n",
    "def convert_array_to_polar(v):\n",
    "    r = tf.norm(v)\n",
    "    phi = tf.atan2(v[1],v[0])\n",
    "    theta = tf.math.acos(v[2],r)\n",
    "    return tf.stack((tf.log(r), phi, theta))\n",
    "\n",
    "def get_input_graph(masses, xtraj, t, noise_level = 0.0, symmetric = True, polar = False):\n",
    "    '''\n",
    "    Convert a given time into a GraphNets graph that can be used to train a model\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    planets : ls\n",
    "        A list of planets using the Body class\n",
    "    xtraj: np.array([num_time_steps, nplanets, 2])\n",
    "        The positions and momenta of the trajectory for each planet\n",
    "    t: int\n",
    "        The time at which the trajectory is evaluated\n",
    "    noise_level: float\n",
    "        Fractional noise added to the training, defaults to 0.05\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    graph_dict: dict\n",
    "        A dictionary containing globals, edges, nodes, senders and receivers\n",
    "    '''\n",
    "    nplanets = len(planets)\n",
    "    nodes, edges, senders, receivers = [], [], [], []\n",
    "    for i in range(nplanets):\n",
    "        noise_mass = np.random.normal(0, noise_level)\n",
    "        #mass = planets[i].mass#*(1+noise_mass)\n",
    "        #nodes.append([mass]) #Use Mercury's mass for units to normalize\n",
    "        nodes.append([masses[i]]) #Use Mercury's mass for units to normalize\n",
    "        for j in range(nplanets):\n",
    "            # I do this instead of if i != j, so the distances and forces are not duplicate, this\n",
    "            # improves the model. I am basically telling the model that F(ij)=F(ji)\n",
    "            if symmetric == True:\n",
    "                if i > j:\n",
    "                    if planets[j].name == 'dummy':\n",
    "                        pass\n",
    "                    else:\n",
    "                        #print(planets[i].name, planets[j].name)\n",
    "                        d = xtraj[t,j,:] - xtraj[t,i,:]\n",
    "                        if polar == True: \n",
    "                            d = cartesian_to_spherical_coordinates(d)\n",
    "                        if noise_level > 0:\n",
    "                            noise_dist = tf.random.normal([3], 0, noise_level, tf.float32) \n",
    "                            edges.append(d*(1+noise_dist))\n",
    "                        else:\n",
    "                            edges.append(d)\n",
    " \n",
    "                        receivers.append(i)\n",
    "                        senders.append(j)\n",
    "            else:\n",
    "                if i != j:\n",
    "                    d = xtraj[t,j,:] - xtraj[t,i,:]\n",
    "                    if noise_level > 0:\n",
    "                        noise_dist = tf.random.normal([3], 0, noise_level, tf.float32) \n",
    "                        edges.append(d*(1+noise_dist))\n",
    "                    else:\n",
    "                        edges.append(d)\n",
    " \n",
    "                    receivers.append(i)\n",
    "                    senders.append(j)\n",
    "\n",
    "    \n",
    "    return{\n",
    "      \"globals\": [G],\n",
    "      \"nodes\": nodes,\n",
    "      \"edges\": edges, \n",
    "      \"receivers\": receivers, \n",
    "      \"senders\": senders \n",
    "    }  \n",
    "\n",
    "def get_momentum_update(output_op, symmetric = True):\n",
    "    reducer = tf.unsorted_segment_sum\n",
    "    \n",
    "    b1 = blocks.ReceivedEdgesToNodesAggregator(reducer=reducer)(output_op)\n",
    "    b2 = blocks.SentEdgesToNodesAggregator(reducer=reducer)(output_op)\n",
    "    if symmetric == True:\n",
    "        dp = b1-b2\n",
    "    else:\n",
    "        dp = b1\n",
    "    return dp\n",
    "\n",
    "def build_rotation_matrix(a,b,g):\n",
    "    A0 = tf.stack([tf.cos(a)*tf.cos(b), tf.sin(a)*tf.cos(b), -tf.sin(b)], \n",
    "                  axis=0)\n",
    "    A1 = tf.stack([tf.cos(a)*tf.sin(b)*tf.sin(g)-tf.sin(a)*tf.cos(g), \n",
    "                   tf.sin(a)*tf.sin(b)*tf.sin(g)+tf.cos(a)*tf.cos(g),\n",
    "                   tf.cos(b)*tf.sin(g)], axis=0)\n",
    "    A2 = tf.stack([tf.cos(a)*tf.sin(b)*tf.cos(g)+tf.sin(a)*tf.sin(g), \n",
    "                   tf.sin(a)*tf.sin(b)*tf.cos(g)-tf.cos(a)*tf.sin(g),\n",
    "                   tf.cos(b)*tf.cos(g)], axis=0)\n",
    "    \n",
    "    return tf.stack((A0, A1, A2), axis=1)\n",
    "\n",
    "def build_rotation_matrix_np(a,b,g):\n",
    "    A0 = np.stack([np.cos(a)*np.cos(b), np.sin(a)*np.cos(b), -np.sin(b)], \n",
    "                  axis=0)\n",
    "    A1 = np.stack([np.cos(a)*np.sin(b)*np.sin(g)-np.sin(a)*np.cos(g), \n",
    "                   np.sin(a)*np.sin(b)*np.sin(g)+np.cos(a)*np.cos(g),\n",
    "                   np.cos(b)*np.sin(g)], axis=0)\n",
    "    A2 = np.stack([np.cos(a)*np.sin(b)*np.cos(g)+np.sin(a)*np.sin(g), \n",
    "                   np.sin(a)*np.sin(b)*np.cos(g)-np.cos(a)*np.sin(g),\n",
    "                   np.cos(b)*np.cos(g)], axis=0)\n",
    "    \n",
    "    return np.stack((A0, A1, A2), axis=1)\n",
    "\n",
    "def convert_graph_to_cartesian(graph):\n",
    "    x = np.exp(graph.edges[:,0])*tf.sin(graph.edges[:,2])*tf.cos(graph.edges[:,1])\n",
    "    y = np.exp(graph.edges[:,0])*tf.sin(graph.edges[:,2])*tf.sin(graph.edges[:,1])\n",
    "    z = np.exp(graph.edges[:,0])*tf.cos(graph.edges[:,2])\n",
    "    newgraph = graph.replace(edges=tf.stack((x,y,z), axis = 1))\n",
    "\n",
    "    return newgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distances(x, input_graph):\n",
    "    '''\n",
    "    Convert positions to distances\n",
    "    '''\n",
    "    new_graph = input_graph.replace(nodes = x)\n",
    "    e1 = blocks.broadcast_sender_nodes_to_edges(new_graph)\n",
    "    e2 = blocks.broadcast_receiver_nodes_to_edges(new_graph)\n",
    "    dx = e1 - e2\n",
    "    return dx\n",
    "\n",
    "def model_gn(dx, input_graph, normalization = 1, symmetric = True):\n",
    "    '''\n",
    "    Use the model to go from dx to dp\n",
    "    '''\n",
    "    graph = input_graph.replace(edges = dx)\n",
    "    outputs = model(graph)\n",
    "    dp_unnorm = get_momentum_update(outputs, symmetric)\n",
    "    dp = dp_unnorm*normalization\n",
    "\n",
    "    forces_unnorm = outputs.edges\n",
    "    forces = forces_unnorm*normalization\n",
    "    return dp, forces\n",
    "\n",
    "def get_leapfrog_step(x0, ph, delta_time, input_graph, model, normalization = 1, symmetric = True):\n",
    "    \n",
    "    delta_x = delta_time/input_graph.nodes\n",
    "    \n",
    "    x1 = x0 + ph*delta_x\n",
    "    \n",
    "    dx = get_distances(x0, input_graph)\n",
    "    \n",
    "    dp, force = model(dx, input_graph, normalization, symmetric)\n",
    "    ph3 = ph + dp\n",
    "\n",
    "    return x1, ph3, dp, force\n",
    "\n",
    "def leapfrog_integration(x0, p0, delta_time, \n",
    "                         input_graph, num_steps, model, \n",
    "                         normalization = 1, symmetric = True):\n",
    "    '''\n",
    "    Learn the orbit through leapfrom integration\n",
    "    '''\n",
    "    def body(i, x0, p0, x_pred, dp_pred, f_pred):\n",
    "        x, ph, dp, force =  get_leapfrog_step(\n",
    "            x0, p0, delta_time, \n",
    "            input_graph, \n",
    "            model, \n",
    "            normalization,\n",
    "            symmetric, )\n",
    "        return i+1, x, ph, x_pred.write(i, x), dp_pred.write(i-1, dp/normalization), f_pred.write(i-1, force)\n",
    "    \n",
    "    # Distance\n",
    "    dx = get_distances(x0, input_graph)\n",
    "\n",
    "    # Model predict*norm_p = F*dt\n",
    "    # (ph = phalf)\n",
    "    dph, fh = model(dx, input_graph, normalization, symmetric)\n",
    "    ph = p0 + 0.5*dph\n",
    "    x = tf.identity(x0)\n",
    "    \n",
    "    i = 0\n",
    "\n",
    "    x_pred = tf.TensorArray(\n",
    "      dtype=tf.float32, size=num_steps, element_shape=x0.shape)\n",
    "    dp_pred = tf.TensorArray(\n",
    "      dtype=tf.float32, size=num_steps-1, element_shape=x0.shape)\n",
    "    f_pred = tf.TensorArray(\n",
    "      dtype=tf.float32, size=num_steps-1, element_shape=fh.shape)\n",
    "\n",
    "    x_pred = x_pred.write(0, x0)\n",
    "    \n",
    "    _, _, _, x_pred, dp_pred, f_pred = tf.while_loop(\n",
    "    lambda i, *unused_args: i < num_steps,\n",
    "        body,\n",
    "        loop_vars = [1, x0, ph, x_pred, dp_pred, f_pred]\n",
    "    )\n",
    "    return x_pred.stack(), dp_pred.stack(), f_pred.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/Pablo/Projets/orbits/conda-env/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# Global constants\n",
    "DAY = 24*3600. # Day in seconds\n",
    "YEAR = 365.25*DAY #Year\n",
    "delta_time = (2/24.)*DAY/YEAR # 1 hour\n",
    "#delta_time = (2/24.) # Planets have units of days, not years!\n",
    "#delta_time = 0.1*DAY/YEAR # 1 hour\n",
    "\n",
    "symmetric = True\n",
    "\n",
    "total_time_traj = 20 #Years\n",
    "num_time_steps_total = int(total_time_traj/delta_time)\n",
    "num_time_steps_test = 10000\n",
    "num_time_steps_test_int = 5000\n",
    "\n",
    "batch_size_tr = 75 # This way an 'Epoch' (when it has gone through all the points) is approximately 1000\n",
    "#batch_size_tr = 50\n",
    "#total_time_tr = 1000*delta_time\n",
    "num_time_steps_tr = int(total_time_traj/delta_time) - num_time_steps_test\n",
    "\n",
    "patience = 10\n",
    "#d_patience = 1e-5\n",
    "d_patience = 0\n",
    "noise_level = 0.05\n",
    "\n",
    "# How much time between logging and printing the current results.\n",
    "log_every_iterations = 1000\n",
    "num_training_iterations = 200000\n",
    "\n",
    "sun = Body()\n",
    "sun.name = 'Sun'\n",
    "sun.mass = 1 # solar masses\n",
    "#sun.mass = 1/(0.33011 * 10**24/MSUN)\n",
    "\n",
    "mercury = Body()\n",
    "mercury.name = 'Mercury'\n",
    "mercury.mass = 0.33011 * 10**24/MSUN # Earth masses\n",
    "#mercury.mass = 1 # Earth masses\n",
    "\n",
    "venus = Body()\n",
    "venus.name = 'Venus'\n",
    "venus.mass = 4.8685 * 10**24/MSUN # Earth masses\n",
    "\n",
    "earth = Body()\n",
    "earth.name = 'Earth'\n",
    "earth.mass =MEARTH/MSUN # Earth masses\n",
    "\n",
    "mars = Body()\n",
    "mars.name = 'Mars'\n",
    "mars.mass =0.642 * 10**24/MSUN # Earth masses\n",
    "\n",
    "jupiter = Body()\n",
    "jupiter.name = 'Jupiter'\n",
    "jupiter.mass =1898.19 * 10**24/MSUN # Earth masses\n",
    "\n",
    "io = Body()\n",
    "io.name = 'Io'\n",
    "io.mass =0.08931900 * 10**24/MSUN # Earth masses\n",
    "\n",
    "europa = Body()\n",
    "europa.name = 'Europa'\n",
    "europa.mass =0.048 * 10**24/MSUN # Earth masses\n",
    "\n",
    "ganymede = Body()\n",
    "ganymede.name = 'Ganymede'\n",
    "ganymede.mass = 0.14819 * 10**24/MSUN # Earth masses\n",
    "\n",
    "callisto = Body()\n",
    "callisto.name = 'Callisto'\n",
    "callisto.mass =0.10759 * 10**24/MSUN # Earth masses\n",
    "\n",
    "saturn = Body()\n",
    "saturn.name = 'Saturn'\n",
    "saturn.mass =568 * 10**24/MSUN # Earth masses\n",
    "\n",
    "dione = Body()\n",
    "dione.name = 'Dione'\n",
    "dione.mass =0.0011 * 10**24/MSUN # Earth masses\n",
    "\n",
    "rhea = Body()\n",
    "rhea.name = 'Rhea'\n",
    "rhea.mass =0.0023 * 10**24/MSUN # Earth masses\n",
    "\n",
    "titan = Body()\n",
    "titan.name = 'Titan'\n",
    "titan.mass =0.135 * 10**24/MSUN # Earth masses\n",
    "\n",
    "uranus = Body()\n",
    "uranus.name = 'Uranus'\n",
    "uranus.mass =86.8 * 10**24/MSUN # Earth masses\n",
    "\n",
    "neptune = Body()\n",
    "neptune.name = 'Neptune'\n",
    "neptune.mass =102 * 10**24/MSUN # Earth masses\n",
    "\n",
    "\n",
    "\n",
    "orbit_sun = np.loadtxt('nasa_orbits/sun_center/sun.txt', usecols = [2,3,4, 5, 6, 7], unpack=True, delimiter=',')\n",
    "orbit_mercury = np.loadtxt('nasa_orbits/sun_center/mercury.txt', usecols = [2,3,4, 5, 6, 7], unpack=True, delimiter=',')\n",
    "orbit_venus = np.loadtxt('nasa_orbits/sun_center/venus.txt', usecols = [2,3,4, 5, 6, 7], unpack=True, delimiter=',')\n",
    "orbit_earth = np.loadtxt('nasa_orbits/sun_center/earth.txt', usecols = [2,3,4, 5, 6, 7], unpack=True, delimiter=',')\n",
    "orbit_mars = np.loadtxt('nasa_orbits/sun_center/mars.txt', usecols = [2,3,4, 5, 6, 7], unpack=True, delimiter=',')\n",
    "orbit_jupiter = np.loadtxt('nasa_orbits/sun_center/jupiter.txt', usecols = [2,3,4, 5, 6, 7], unpack=True, delimiter=',')\n",
    "orbit_io = np.loadtxt('nasa_orbits/sun_center/io.txt', usecols = [2,3,4, 5, 6, 7], unpack=True, delimiter=',')\n",
    "orbit_europa = np.loadtxt('nasa_orbits/sun_center/europa.txt', usecols = [2,3,4, 5, 6, 7], unpack=True, delimiter=',')\n",
    "orbit_ganymede = np.loadtxt('nasa_orbits/sun_center/ganymede.txt', usecols = [2,3,4, 5, 6, 7], unpack=True, delimiter=',')\n",
    "orbit_callisto = np.loadtxt('nasa_orbits/sun_center/callisto.txt', usecols = [2,3,4, 5, 6, 7], unpack=True, delimiter=',')\n",
    "orbit_saturn = np.loadtxt('nasa_orbits/sun_center/saturn.txt', usecols = [2,3,4, 5, 6, 7], unpack=True, delimiter=',')\n",
    "orbit_dione = np.loadtxt('nasa_orbits/sun_center/dione.txt', usecols = [2,3,4, 5, 6, 7], unpack=True, delimiter=',')\n",
    "orbit_rhea = np.loadtxt('nasa_orbits/sun_center/rhea.txt', usecols = [2,3,4, 5, 6, 7], unpack=True, delimiter=',')\n",
    "orbit_titan = np.loadtxt('nasa_orbits/sun_center/titan.txt', usecols = [2,3,4, 5, 6, 7], unpack=True, delimiter=',')\n",
    "orbit_uranus = np.loadtxt('nasa_orbits/sun_center/uranus.txt', usecols = [2,3,4, 5, 6, 7], unpack=True, delimiter=',')\n",
    "orbit_neptune = np.loadtxt('nasa_orbits/sun_center/neptune.txt', usecols = [2,3,4, 5, 6, 7], unpack=True, delimiter=',')\n",
    "\n",
    "masses = np.array([sun.mass, mercury.mass, venus.mass, earth.mass, mars.mass,\n",
    "                   jupiter.mass + io.mass + europa.mass + ganymede.mass + callisto.mass, \n",
    "                   saturn.mass + dione.mass + rhea.mass + titan.mass, \n",
    "                   uranus.mass, neptune.mass\n",
    "                  ])\n",
    "\n",
    "\n",
    "orbit_jupiter[:,:] += (orbit_io[:,:]*io.mass + orbit_europa[:,:]*europa.mass + \n",
    "                       orbit_ganymede[:,:]*ganymede.mass + orbit_callisto[:,:]*callisto.mass)/jupiter.mass\n",
    "\n",
    "\n",
    "orbit_saturn[:,:] += (orbit_dione[:,:]*dione.mass + orbit_rhea[:,:]*rhea.mass + \n",
    "                       orbit_titan[:,:]*titan.mass)/saturn.mass\n",
    "\n",
    "orbits_orig = np.stack([orbit_sun, orbit_mercury, orbit_venus, orbit_earth, orbit_mars,\n",
    "                   orbit_jupiter, orbit_saturn, orbit_uranus, orbit_neptune\n",
    "                       ])\n",
    "\n",
    "orbits_orig[:,3:,:] *= 365.25\n",
    "\n",
    "jupiter.mass = masses[5]\n",
    "saturn.mass = masses[6]\n",
    "\n",
    "x_traj_np, p_traj_np = change_orbit_frame(orbits_orig[:7], masses[:7], delta_time)\n",
    "\n",
    "\n",
    "sun.pos = x_traj_np[0,:,0]\n",
    "mercury.pos = x_traj_np[1,:,0]\n",
    "venus.pos = x_traj_np[2,:,0]\n",
    "earth.pos = x_traj_np[3,:,0]\n",
    "mars.pos =x_traj_np[4,:,0]\n",
    "jupiter.pos = x_traj_np[5,:,0]\n",
    "io.pos = x_traj_np[6,:,0]\n",
    "europa.pos = x_traj_np[7,:,0]\n",
    "ganymede.pos = x_traj_np[8,:,0]\n",
    "callisto.pos = x_traj_np[9,:,0]\n",
    "saturn.pos = x_traj_np[6,:,0]\n",
    "uranus.pos = x_traj_np[7,:,0]\n",
    "neptune.pos = x_traj_np[8,:,0]\n",
    "\n",
    "sun.mom = p_traj_np[0,:,0]\n",
    "mercury.mom = p_traj_np[1,:,0]\n",
    "venus.mom = p_traj_np[2,:,0]\n",
    "earth.mom = p_traj_np[3,:,0]\n",
    "mars.mom =p_traj_np[4,:,0]\n",
    "jupiter.mom = p_traj_np[5,:,0]\n",
    "io.mom = p_traj_np[6,:,0]\n",
    "europa.mom = p_traj_np[7,:,0]\n",
    "ganymede.mom = p_traj_np[8,:,0]\n",
    "callisto.mom = p_traj_np[9,:,0]\n",
    "saturn.mom = p_traj_np[6,:,0]\n",
    "uranus.mom = p_traj_np[7,:,0]\n",
    "neptune.mom = p_traj_np[8,:,0]\n",
    "\n",
    "planets = [sun, mercury,\n",
    "           venus, \n",
    "           earth, mars, \n",
    "           jupiter,\n",
    "           saturn, \n",
    "           #uranus, neptune\n",
    "          ]\n",
    "\n",
    "nplanets = len(planets)\n",
    "logmasses_ini = -6*np.ones(nplanets)\n",
    "logmasses_ini[0] = -0.5\n",
    "#mean_logmasses_ini = tf.convert_to_tensor(np.random.uniform(low=-7.0, high=0.0, size=nplanets),dtype = np.float32)\n",
    "mean_logmasses_ini = tf.convert_to_tensor(logmasses_ini,dtype = np.float32)\n",
    "#mean_logmasses_ini = tf.convert_to_tensor(-2*np.ones(nplanets),dtype = np.float32)\n",
    "#mean_logmasses_ini = tf.convert_to_tensor(np.log(masses[:nplanets]/earth.mass),dtype = np.float32)\n",
    "delta_logmasses = tf.random.normal([nplanets], 0, 0.1, tf.float32)\n",
    "mean_logmasses_ini = mean_logmasses_ini+delta_logmasses\n",
    "sigma_logmasses_ini = tf.convert_to_tensor(np.ones(nplanets),dtype = np.float32)\n",
    "#masses_tr = tf.convert_to_tensor(np.log(masses[:nplanets]),dtype = np.float32)\n",
    "\n",
    "planets_gn = deepcopy(planets)\n",
    "\n",
    "dp_traj_np = p_traj_np[1:] - p_traj_np[:-1]\n",
    "dv_traj_np = dp_traj_np/masses[np.newaxis, :nplanets, np.newaxis]\n",
    "\n",
    "p_norm = np.std(dp_traj_np)\n",
    "v_norm = np.std(dv_traj_np)\n",
    "#p_norm = 1\n",
    "\n",
    "x_traj_test = tf.convert_to_tensor(x_traj_np[:num_time_steps_test], dtype=np.float32)\n",
    "p_traj_test = tf.convert_to_tensor(p_traj_np[:num_time_steps_test], dtype=np.float32)\n",
    "dp_traj_norm = tf.convert_to_tensor(\n",
    "    dp_traj_np[:num_time_steps_test-1]/p_norm, dtype=np.float32)\n",
    "dv_traj_norm = tf.convert_to_tensor(\n",
    "    dv_traj_np[:num_time_steps_test-1]/v_norm, dtype=np.float32)\n",
    "\n",
    "\n",
    "\n",
    "x_traj_np_tr = x_traj_np[num_time_steps_test:]\n",
    "dp_traj_np_tr = dp_traj_np[num_time_steps_test:]/p_norm\n",
    "dv_traj_np_tr = dv_traj_np[num_time_steps_test:]/v_norm\n",
    "\n",
    "\n",
    "#dv_traj_np_tr[:,0]*=1e7\n",
    "#x_traj_np_tr[:,0]*=1e7\n",
    "\n",
    "input_dict_test = get_input_graph(masses, x_traj_test, 0, noise_level = 0.0, symmetric = symmetric)\n",
    "\n",
    "input_graph_test = utils_tf.data_dicts_to_graphs_tuple([input_dict_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        , -6.77995863, -5.61122214, -5.52233756, -6.49108229,\n",
       "       -3.0201877 , -3.54416317, -4.36009759, -4.29001714])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log10(masses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph network.\n",
    "graph_net_module = blocks.EdgeBlock(\n",
    "        #edge_model_fn=lambda: snt.nets.MLP([128, 128, 128, 128, 3]),\n",
    "    #edge_model_fn=lambda: snt.Linear(output_size=3),\n",
    "    edge_model_fn=lambda: snt.nets.MLP([32, 32, 3]), \n",
    "    use_edges = True,\n",
    "    use_receiver_nodes = True,\n",
    "    use_sender_nodes = True,\n",
    "    use_globals = False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/Pablo/Projets/orbits/conda-env/lib/python3.7/site-packages/sonnet/python/modules/basic.py:127: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/Pablo/Projets/orbits/conda-env/lib/python3.7/site-packages/sonnet/python/modules/basic.py:132: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From <ipython-input-8-8ba5187a716b>:51: calling norm (from tensorflow.python.ops.linalg_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "x_traj_tr, dv_traj_tr = generate_batch_random(planets, x_traj_np_tr, dv_traj_np_tr, num_time_steps=num_time_steps_tr, batch_size=batch_size_tr)\n",
    "\n",
    "t = tf.random_uniform([], minval=0, maxval=num_time_steps_tr - 1, dtype=tf.int32)\n",
    "\n",
    "# I think the maxes should be 2pi, pi, pi\n",
    "alpha = tf.random_uniform([], minval=0, maxval=2*np.pi, dtype=tf.dtypes.float32)\n",
    "beta = tf.random_uniform([], minval=0, maxval=np.pi, dtype=tf.dtypes.float32)\n",
    "gamma = tf.random_uniform([], minval=0, maxval=np.pi, dtype=tf.dtypes.float32)\n",
    "R = build_rotation_matrix(alpha,beta,gamma)\n",
    "\n",
    "input_dict_tr = []\n",
    "x_traj_tr_rot = tf.einsum('ijkl,lm->ijkm', x_traj_tr,R)\n",
    "#x_traj_tr_rot = x_traj_tr\n",
    "\n",
    "mean_logmasses_tr = tf.Variable(mean_logmasses_ini, trainable = True)\n",
    "#sigma_logmasses_tr = tf.Variable(sigma_logmasses_ini, trainable = True)\n",
    "#rand_tr = tf.random.normal([nplanets], 0, 1, tf.float32)\n",
    "#logmasses_tr = mean_logmasses_tr + sigma_logmasses_tr*rand_tr\n",
    "logmasses_tr = mean_logmasses_tr\n",
    "\n",
    "#masses_tf = tf.convert_to_tensor(np.log(masses[:nplanets]/mercury.mass), dtype=tf.dtypes.float32)\n",
    "for i in range(batch_size_tr):\n",
    "    input_dict_tr.append(get_input_graph(logmasses_tr, x_traj_tr_rot[i], t, noise_level = noise_level, symmetric=symmetric, polar = True))\n",
    "\n",
    "    \n",
    "input_pos_tr = x_traj_tr_rot[:,t]\n",
    "input_graph_tr = utils_tf.data_dicts_to_graphs_tuple(input_dict_tr)\n",
    "#logmass_graph_tr = graph_net_module_1(input_graph_tr)\n",
    "#mass_graph_tr = logmass_graph_tr.replace(nodes = tf.exp(logmass_graph_tr.nodes))\n",
    "\n",
    "#new_graph = average_masses(output_model, batch_size_tr, nplanets)\n",
    "#input_graph_tr = input_graph_tr.replace(nodes = new_graph.nodes)\n",
    "forces_graph_tr_sph = graph_net_module(input_graph_tr)\n",
    "forces_graph_tr = forces_graph_tr_sph.replace(edges = spherical_to_cartesian_coordinates(forces_graph_tr_sph.edges))\n",
    "\n",
    "b1_tr = blocks.ReceivedEdgesToNodesAggregator(reducer = tf.unsorted_segment_sum)(forces_graph_tr)\n",
    "b2_tr = blocks.SentEdgesToNodesAggregator(reducer = tf.unsorted_segment_sum)(forces_graph_tr)\n",
    "summed_forces_tr = b1_tr-b2_tr\n",
    "\n",
    "#newnodes_tr = tf.concat([forces_graph_tr.nodes, summed_forces_tr], axis = 1)\n",
    "\n",
    "#summed_forces_graph_tr = forces_graph_tr.replace(nodes=newnodes_tr)\n",
    "\n",
    "#acceleration_graph_tr = graph_net_module_3(summed_forces_graph_tr)\n",
    "\n",
    "acceleration_tr = tf.divide(summed_forces_tr, tf.pow(forces_graph_tr.nodes, 10))\n",
    "output_ops_tr = tf.reshape(acceleration_tr, shape=[batch_size_tr, nplanets, 3])\n",
    "#output_ops_tr = tf.reshape(acceleration_graph_tr.nodes, shape=[batch_size_tr, nplanets, 3])\n",
    "target_nodes_tr = tf.einsum('ijk,kl->ijl', dv_traj_tr[:,t],R)\n",
    "\n",
    "norm_tf = tf.reduce_mean(tf.norm(target_nodes_tr, axis = 2,  keep_dims=True),axis=0)\n",
    "dp_tr = (output_ops_tr - target_nodes_tr)/norm_tf*tf.reduce_mean(norm_tf)\n",
    "loss_op_tr = tf.reduce_mean(\n",
    "    tf.reduce_sum(\n",
    "    (dp_tr)**2., axis = -1\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def force_newton(x, m1, m2):\n",
    "    return G*m1*m2/np.linalg.norm(x, keepdims=True)**3.*x\n",
    "\n",
    "nforce = 200\n",
    "rand_force = np.random.choice(np.arange(0,num_time_steps_test), nforce, replace=False)\n",
    "rand_angle_1 = np.random.uniform(low = 0, high = 2*np.pi, size = nforce)\n",
    "rand_angle_2 = np.random.uniform(low = 0, high = np.pi, size = nforce)\n",
    "rand_angle_3 = np.random.uniform(low = 0, high = np.pi, size = nforce)\n",
    "positions = np.empty([nforce, nplanets, 3])\n",
    "dv_val_np_true = np.empty([nforce, nplanets, 3])\n",
    "forces_true = np.empty([nplanets - 1, nforce, 3])\n",
    "planets_forces = deepcopy(planets)\n",
    "for i in range(nforce):\n",
    "    j = rand_force[i]\n",
    "    rot_mat = build_rotation_matrix_np(rand_angle_1[i],\n",
    "                                      rand_angle_2[i],\n",
    "                                      rand_angle_3[i])\n",
    "    positions[i,:,:] = x_traj_np[j].dot(rot_mat)\n",
    "    dv_val_np_true[i,:,:] = dv_traj_np[j].dot(rot_mat)\n",
    "    for p in range(nplanets):\n",
    "        if p > 0: \n",
    "            forces_true[p-1,i,:] = force_newton(positions[i,p,:] - positions[i,0,:], 1, planets_forces[p].mass)\n",
    "\n",
    "        #if p == 0:\n",
    "            #positions[i,p,:] = np.zeros(planets_forces[0].pos[:3].shape)\n",
    "        #else:\n",
    "            #positions[i,p,:] = (x_traj_np[j,p] - x_traj_np[j,0]).dot(rot_mat)\n",
    "            #forces_true[p-1,i,:] = force_newton(positions[i,p,:], 1, planets_forces[p].mass)\n",
    "\n",
    "\n",
    "x_force = tf.convert_to_tensor(positions, dtype = np.float32)\n",
    "dv_val_true = tf.convert_to_tensor(dv_val_np_true/v_norm, dtype = np.float32)\n",
    "input_dict_val = []\n",
    "for i in range(nforce):\n",
    "    input_dict_val.append(get_input_graph(logmasses_tr, x_force, i, noise_level = noise_level, polar = True))\n",
    "\n",
    "input_graph_val = utils_tf.data_dicts_to_graphs_tuple(input_dict_val)\n",
    "#logmass_graph_val = graph_net_module_1(input_graph_val)\n",
    "#mass_graph_val = logmass_graph_val.replace(nodes = tf.exp(logmass_graph_val.nodes))\n",
    "\n",
    "#new_graph = average_masses(output_model, batch_size_tr, nplanets)\n",
    "#input_graph_tr = input_graph_tr.replace(nodes = new_graph.nodes)\n",
    "forces_graph_val_sph = graph_net_module(input_graph_val)\n",
    "forces_graph_val = forces_graph_val_sph.replace(edges=spherical_to_cartesian_coordinates(forces_graph_val_sph.edges))\n",
    "\n",
    "b1_val = blocks.ReceivedEdgesToNodesAggregator(reducer = tf.unsorted_segment_sum)(forces_graph_val)\n",
    "b2_val = blocks.SentEdgesToNodesAggregator(reducer = tf.unsorted_segment_sum)(forces_graph_val)\n",
    "summed_forces_val = b1_val-b2_val\n",
    "#newnodes_val = tf.concat([forces_graph_val.nodes, summed_forces_val], axis = 1)\n",
    "\n",
    "#summed_forces_graph_val = forces_graph_tr.replace(nodes=newnodes_val)\n",
    "\n",
    "#acceleration_graph_val = graph_net_module_3(summed_forces_graph_val)\n",
    "acceleration_val = tf.divide(summed_forces_val, tf.pow(forces_graph_val.nodes, 10))\n",
    "\n",
    "#output_ops_tr = get_momentum_update(output_model, symmetric = symmetric)\n",
    " \n",
    "dv_val_pred = tf.reshape(acceleration_val, shape=[nforce, nplanets, 3])\n",
    "\n",
    "force_val = tf.reshape(forces_graph_val.edges, shape=[nforce, nplanets*(nplanets - 1)//2, 3])\n",
    "\n",
    "dp_val = (dv_val_pred - dv_val_true)/norm_tf*tf.reduce_mean(norm_tf)\n",
    "loss_val = tf.reduce_mean(\n",
    "    tf.reduce_sum(\n",
    "    (dp_val)**2., axis = -1\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning rate makes a HUGE difference. If it is oscillating around a certain number (e.g. 1.4), it needs to be lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ninitial_learning_rate = 0.1\\ndecay_steps = 1.0\\ndecay_rate = 0.5\\nlearning_rate_fn = keras.optimizers.schedules.InverseTimeDecay(\\n  initial_learning_rate, decay_steps, decay_rate)\\n\\n# Define configuration parameters\\nstart_lr = 0.01\\nmin_lr = 0.00001\\nmax_lr = 0.1\\nrampup_epochs = 10\\nsustain_epochs = 0\\nexp_decay = 0.8\\n\\n# Define the scheduling function\\ndef schedule(epoch):\\n    def lr(epoch, start_lr, min_lr, max_lr, rampup_epochs, sustain_epochs, exp_decay):\\n        if epoch < rampup_epochs:\\n            lr = (max_lr - start_lr)/rampup_epochs * epoch + start_lr\\n        elif epoch < rampup_epochs + sustain_epochs:\\n            lr = max_lr\\n        else:\\n            lr = (max_lr - min_lr) * exp_decay**(epoch-rampup_epochs-sustain_epochs) + min_lr\\n        return lr\\n    return lr(epoch, start_lr, min_lr, max_lr, rampup_epochs, sustain_epochs, exp_decay)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "initial_learning_rate = 0.1\n",
    "decay_steps = 1.0\n",
    "decay_rate = 0.5\n",
    "learning_rate_fn = keras.optimizers.schedules.InverseTimeDecay(\n",
    "  initial_learning_rate, decay_steps, decay_rate)\n",
    "\n",
    "# Define configuration parameters\n",
    "start_lr = 0.01\n",
    "min_lr = 0.00001\n",
    "max_lr = 0.1\n",
    "rampup_epochs = 10\n",
    "sustain_epochs = 0\n",
    "exp_decay = 0.8\n",
    "\n",
    "# Define the scheduling function\n",
    "def schedule(epoch):\n",
    "    def lr(epoch, start_lr, min_lr, max_lr, rampup_epochs, sustain_epochs, exp_decay):\n",
    "        if epoch < rampup_epochs:\n",
    "            lr = (max_lr - start_lr)/rampup_epochs * epoch + start_lr\n",
    "        elif epoch < rampup_epochs + sustain_epochs:\n",
    "            lr = max_lr\n",
    "        else:\n",
    "            lr = (max_lr - min_lr) * exp_decay**(epoch-rampup_epochs-sustain_epochs) + min_lr\n",
    "        return lr\n",
    "    return lr(epoch, start_lr, min_lr, max_lr, rampup_epochs, sustain_epochs, exp_decay)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer.\n",
    "learning_rate = 1e-3\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)#, amsgrad=True)\n",
    "step_op = optimizer.minimize(loss_op_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell resets the Tensorflow session, but keeps the same computational\n",
    "# graph.\n",
    "\n",
    "try:\n",
    "    sess.close()\n",
    "except NameError:\n",
    "    pass\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "nsteps_no_improvement = 0\n",
    "last_iteration = 0\n",
    "best_loss = 1e100\n",
    "iterations = []\n",
    "losses_tr = []\n",
    "losses_val = []\n",
    "losses_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.49256682, -6.128961  , -5.9554133 , -6.143643  , -6.1051598 ,\n",
       "       -6.070259  , -6.038288  ], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmasses_tr.eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# (iteration number), T (elapsed seconds), Ltr (training 1-step loss), Ltest (test loss)\n",
      "# 000000, T 140.0, Ltr 79885498352402432.000000, Lval 6699404341805056.000000 , Msun -0.493567 , Mmerc -6.127961, \n",
      "# 001000, T 375.3, Ltr 87745480.000000, Lval 155455856.000000 , Msun -0.498893 , Mmerc -6.122274, \n",
      "# 002000, T 612.7, Ltr 2580.005859, Lval 7069.189453 , Msun -0.498893 , Mmerc -6.122274, \n",
      "# 003000, T 848.1, Ltr 223.450104, Lval 1366.173340 , Msun -0.498893 , Mmerc -6.122274, \n",
      "# 004000, T 1090.1, Ltr 5.010312, Lval 634.778381 , Msun -0.498893 , Mmerc -6.122274, \n",
      "# 005000, T 1338.6, Ltr 1346.288818, Lval 353.745758 , Msun -0.498893 , Mmerc -6.122274, \n",
      "# 006000, T 1584.6, Ltr 10.871880, Lval 199.674683 , Msun -0.498893 , Mmerc -6.122274, \n",
      "# 007000, T 1830.6, Ltr 12.210464, Lval 112.340790 , Msun -0.498893 , Mmerc -6.122274, \n",
      "# 008000, T 2075.8, Ltr 2.788873, Lval 57.140526 , Msun -0.498893 , Mmerc -6.122274, \n",
      "# 009000, T 2319.2, Ltr 1.023803, Lval 65.409706 , Msun -0.498893 , Mmerc -6.122274, \n",
      "# 010000, T 2556.3, Ltr 35.245926, Lval 38.709526 , Msun -0.498893 , Mmerc -6.122274, \n",
      "# 011000, T 2791.5, Ltr 0.907044, Lval 13.070189 , Msun -0.498893 , Mmerc -6.122274, \n",
      "# 012000, T 3023.0, Ltr 9.724848, Lval 6.745886 , Msun -0.498893 , Mmerc -6.122274, \n",
      "# 013000, T 3259.9, Ltr 2.256042, Lval 3.080740 , Msun -0.498893 , Mmerc -6.122274, \n",
      "# 014000, T 3499.7, Ltr 0.831298, Lval 2.749623 , Msun -0.498893 , Mmerc -6.122274, \n",
      "# 015000, T 3745.9, Ltr 1.063271, Lval 1.459387 , Msun -0.498893 , Mmerc -6.122274, \n",
      "# 016000, T 3992.8, Ltr 1.424819, Lval 1.341127 , Msun -0.498893 , Mmerc -6.122274, \n",
      "# 017000, T 4231.9, Ltr 0.798911, Lval 1.130636 , Msun -0.498893 , Mmerc -6.122274, \n",
      "# 018000, T 4464.5, Ltr 1.398056, Lval 1.177885 , Msun -0.498893 , Mmerc -6.122274, \n",
      "# 019000, T 4694.7, Ltr 0.786157, Lval 0.998755 , Msun -0.498893 , Mmerc -6.122274, \n",
      "# 020000, T 4926.1, Ltr 0.768196, Lval 0.969470 , Msun -0.498893 , Mmerc -6.122274, \n",
      "# 021000, T 5157.7, Ltr 0.694711, Lval 0.970966 , Msun -0.498893 , Mmerc -6.122274, \n",
      "# 022000, T 5393.0, Ltr 0.657444, Lval 0.965512 , Msun -0.498893 , Mmerc -6.122274, \n",
      "# 023000, T 5626.4, Ltr 0.704350, Lval 0.857131 , Msun -0.498893 , Mmerc -6.122274, \n",
      "# 024000, T 5859.9, Ltr 0.677212, Lval 0.852000 , Msun -0.498893 , Mmerc -6.122274, \n",
      "# 025000, T 6094.1, Ltr 0.733961, Lval 0.849399 , Msun -0.498893 , Mmerc -6.122274, \n",
      "# 026000, T 6328.8, Ltr 0.690410, Lval 0.836161 , Msun -0.498893 , Mmerc -6.122274, \n",
      "# 027000, T 6564.3, Ltr 0.641055, Lval 0.806001 , Msun -0.498893 , Mmerc -6.122274, \n",
      "# 028000, T 6799.9, Ltr 0.820032, Lval 1.250252 , Msun -0.498893 , Mmerc -6.122274, \n",
      "# 029000, T 7037.0, Ltr 0.627910, Lval 0.768860 , Msun -0.498893 , Mmerc -6.122274, \n",
      "# 030000, T 7276.5, Ltr 0.696456, Lval 0.805648 , Msun -0.498893 , Mmerc -6.122274, \n",
      "# 031000, T 7517.6, Ltr 0.620466, Lval 0.813503 , Msun -0.498893 , Mmerc -6.122274, \n",
      "# 032000, T 7758.9, Ltr 0.700333, Lval 0.749461 , Msun -0.498893 , Mmerc -6.122274, \n",
      "# 033000, T 8007.7, Ltr 0.669847, Lval 0.753784 , Msun -0.498893 , Mmerc -6.122274, \n",
      "# 034000, T 8302.2, Ltr 0.603064, Lval 0.763770 , Msun -0.498893 , Mmerc -6.122274, \n",
      "# 035000, T 8577.6, Ltr 0.580085, Lval 0.802885 , Msun -0.498893 , Mmerc -6.122274, \n",
      "# 036000, T 8845.6, Ltr 0.608699, Lval 0.774043 , Msun -0.498893 , Mmerc -6.122274, \n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "last_log_time = start_time\n",
    "\n",
    "print(\"# (iteration number), T (elapsed seconds), \"\n",
    "      \"Ltr (training 1-step loss), Ltest (test loss)\")\n",
    "\n",
    "for iteration in range(last_iteration, num_training_iterations):\n",
    "    last_iteration = iteration\n",
    "    train_values = sess.run({\n",
    "        \"step\": step_op,\n",
    "        \"loss\": loss_op_tr,\n",
    "        \"input_pos\": input_pos_tr,\n",
    "        \"input_graph\": input_graph_tr,\n",
    "        \"target_nodes\": target_nodes_tr,\n",
    "        \"outputs\": output_ops_tr,\n",
    "        \"mean_logmasses\": logmasses_tr,\n",
    "        #\"sigma_logmasses\": sigma_logmasses_tr,\n",
    "    })\n",
    "    \n",
    "    the_time = time.time()\n",
    "    \n",
    "    if iteration%log_every_iterations == 0:\n",
    "        val_values = sess.run({\n",
    "            \"output\": dv_val_pred,\n",
    "            \"target\": dv_val_true,\n",
    "            \"force\": force_val,\n",
    "            \"summed_forces\": summed_forces_val,\n",
    "            \"loss\": loss_val,\n",
    "            })\n",
    "        #test_orbit = sess.run({\n",
    "        #    \"x_pred\": xp, \n",
    "        #    \"dp_pred\": pp,\n",
    "        #    \"f_pred\": output_force,\n",
    "        #    \"loss\": loss_test\n",
    "        #})\n",
    "\n",
    "        #learning_rate = one_cycle_lr(iteration, learning_rate, min_lr, max_lr, rampup_epochs, sustain_epochs, exp_decay)\n",
    "        #optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "        \n",
    "        # Implement early stopping\n",
    "        if val_values[\"loss\"] > best_loss: \n",
    "            nsteps_no_improvement += 1\n",
    "        else: \n",
    "            save_sess= sess # save session\n",
    "            nsteps_no_improvement = 0\n",
    "            best_loss = val_values[\"loss\"]\n",
    "            \n",
    "        # If we have reached early stopping, stop the training\n",
    "        if nsteps_no_improvement >= patience: \n",
    "            train_values = save_sess.run({\n",
    "                \"step\": step_op,\n",
    "                \"loss\": loss_op_tr,\n",
    "                \"input_pos\": input_pos_tr,\n",
    "                \"input_graph\": input_graph_tr,\n",
    "                \"target_nodes\": target_nodes_tr,\n",
    "                \"outputs\": output_ops_tr,\n",
    "                \"mean_logmasses\": logmasses_tr,\n",
    "            })\n",
    "\n",
    "            val_values = save_sess.run({\n",
    "                \"output\": dv_val_pred,\n",
    "                \"target\": dv_val_true,\n",
    "                \"force\": force_val,\n",
    "                \"summed_forces\": summed_forces_val,\n",
    "                \"loss\": loss_val,\n",
    "            })\n",
    "            \n",
    "            print('Convergence achieved')\n",
    "            print('Iterations = ', iteration)\n",
    "            print('Time = ', time.time() - start_time, 'seconds.')\n",
    "            print('Training 1-step loss = ', train_values[\"loss\"])\n",
    "            break\n",
    "    \n",
    "            \n",
    "        last_log_time = the_time\n",
    "        elapsed = time.time() - start_time\n",
    "        iterations.append(iteration)\n",
    "        losses_tr.append(train_values[\"loss\"])\n",
    "        losses_val.append(val_values[\"loss\"])\n",
    "        #losses_test.append(test_orbit[\"loss\"])\n",
    "        #print(\n",
    "        #    \"# {:06d}, T {:.1f}, Ltr {:.6f}, Lval {:.6f}, Ltest {:.6f}\".format(\n",
    "        #        iteration,  elapsed, train_values[\"loss\"], train_values[\"val_loss\"], test_orbit[\"loss\"]))\n",
    "        \n",
    "        print(\n",
    "            \"# {:06d}, T {:.1f}, Ltr {:.6f}, Lval {:.6f} , Msun {:.6f} , Mmerc {:.6f}, \".format(\n",
    "                iteration,  elapsed, train_values[\"loss\"], val_values[\"loss\"], \n",
    "            train_values[\"mean_logmasses\"][0], train_values[\"mean_logmasses\"][1]\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_path = saver.save(sess, \"./model.ckpt\")\n",
    "#print(\"Model saved in path: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = train_values[\"target_nodes\"]\n",
    "ou = train_values[\"outputs\"]\n",
    "#masses_learned = train_values[\"masses\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(nplanets):\n",
    "    plt.scatter(tr[:,i,0], tr[:,i,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(nplanets):\n",
    "    plt.scatter(ou[:,i,0], ou[:,i,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = val_values[\"output\"]\n",
    "val_truth = val_values[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(nplanets):\n",
    "    plt.scatter(val_pred[:,i,0], val_pred[:,i,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(nplanets):\n",
    "    plt.scatter(val_truth[:,i,0], val_truth[:,i,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_force = val_values[\"force\"]\n",
    "val_masses = 10**(train_values[\"mean_logmasses\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [0,1,3,6,10,15,21]\n",
    "X = np.zeros([(nplanets-1)*nforce,5])\n",
    "F = np.zeros([(nplanets-1)*nforce,3])\n",
    "F_norm = np.mean(val_force)\n",
    "for i in range(nplanets-1):\n",
    "    #print( X[i*nforce:(i+1)*nforce].shape, positions[:,i+1,:].shape)\n",
    "    X[i*nforce:(i+1)*nforce,0] = val_masses[i+1]\n",
    "    X[i*nforce:(i+1)*nforce,1:4] = positions[:,i+1,:]\n",
    "    X[i*nforce:(i+1)*nforce,4] = np.linalg.norm(positions[:,i+1,:], axis = -1)#**3\n",
    "    #F[i*nforce:(i+1)*nforce,:] = forces_true[i,:,:]#/F_norm\n",
    "    F[i*nforce:(i+1)*nforce,:] = val_force[:,indices[i],:]/F_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysr import pysr\n",
    "# Learn equations\n",
    "equations_y = pysr(X[:,:5], F[:,1], niterations=100,\n",
    "            binary_operators=[\"mult\", \"div\"],\n",
    "            unary_operators=[\"square\", \"cube\", \"sqrtm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equations_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equations_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-np.arange(nplanets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_logmasses_ini.eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:conda-env-3] *",
   "language": "python",
   "name": "conda-env-conda-env-3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
